<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Gender-typed Preference Bias in Recommender Systems</title>
  <link rel="stylesheet" href="assets/css/style.css" />
  <style>
    body {
      margin: 0;
      font-family: 'Segoe UI', Arial, sans-serif;
      color: #234375;
      background: #f4f7fb;
    }
    .banner {
      background: #234375;
      padding: 0;
      margin: 0;
      min-height: 84px;
      display: flex;
      align-items: center;
      position: relative;
      z-index: 10;
    }
    .banner-inner {
      max-width: 1100px;
      margin: 0 auto;
      display: flex;
      align-items: center;
      min-height: 84px;
    }
    .banner a {
      display: flex;
      align-items: center;
      margin-right: 1.2rem;
      text-decoration: none;
      cursor: pointer;
    }
    .banner img {
      height: 44px;
      width: auto;
      margin-right: 1rem;
      border-radius: 6px;
      box-shadow: 0 1px 4px rgba(60,42,86,0.07);
    }
    .banner span {
      font-family: 'Georgia', 'Times New Roman', serif;
      font-size: 1.55rem;
      font-weight: 500;
      color: #fff;
      letter-spacing: 0.5px;
    }
    nav {
      flex: 1;
      display: flex;
      justify-content: center;
      align-items: center;
    }
    nav a {
      color: #fff;
      text-decoration: none;
      margin: 0 1.2rem;
      font-weight: 500;
      font-size: 1.13rem;
      padding: 0.45em 1em;
      border-radius: 6px;
      transition: background 0.2s, color 0.2s;
    }
    nav a:hover, nav a:focus {
      background: #e3eaff;
      color: #234375;
      outline: none;
    }

    /* HERO SECTION */
    .hero-section {
      position: relative;
      width: 100%;
      max-width: 100%;
      margin: 2.5rem 0 2.5rem 0;
      border-radius: 22px;
      overflow: hidden;
      box-shadow: 0 6px 32px rgba(35,67,117,0.13), 0 2px 8px rgba(60,42,86,0.10);
      background: linear-gradient(135deg, #7c3aed 0%, #8b5cf6 50%, #a78bfa 100%);
      min-height: 280px;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .hero-content {
      text-align: center;
      padding: 2.5rem;
      color: white;
    }
    .hero-content h1 {
      font-size: 1.9rem;
      margin: 0 0 0.8rem 0;
      font-weight: 700;
      text-shadow: 0 2px 8px rgba(0,0,0,0.2);
    }
    .hero-content .subtitle {
      font-size: 1.15rem;
      opacity: 0.9;
      max-width: 700px;
      margin: 0 auto;
    }
    .hero-icon {
      font-size: 4rem;
      margin-bottom: 1rem;
      opacity: 0.9;
    }

    main {
      max-width: 1100px;
      margin: 0 auto 2.5rem auto;
      background: linear-gradient(90deg, #f4f7fb 80%, #e3eaff 100%);
      border-radius: 14px;
      box-shadow: 0 2px 8px rgba(60,42,86,0.05);
      padding: 2.2rem 2rem 2rem 2rem;
      display: flex;
      gap: 2.5rem;
    }
    .project-main {
      flex: 2;
      min-width: 0;
    }
    .project-meta {
      flex: 1;
      min-width: 260px;
      max-width: 340px;
      background: #f8fafd;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(35,67,117,0.07);
      padding: 1.5rem 1.2rem 1.2rem 1.2rem;
      margin-top: 0.5rem;
      margin-bottom: 0.5rem;
      display: flex;
      flex-direction: column;
      gap: 1.3rem;
      height: fit-content;
    }
    .project-meta h3 {
      font-size: 1.08rem;
      color: #234375;
      margin-bottom: 0.5rem;
      font-weight: 600;
      letter-spacing: 0.2px;
    }
    .project-meta .project-tags {
      font-size: 0.98rem;
      color: #6b7a99;
      font-style: italic;
      margin-bottom: 0.2rem;
    }
    .project-meta .project-tags span {
      margin-right: 0.7em;
      font-size: 1em;
      font-style: italic;
      font-weight: 400;
      display: inline;
    }
    .project-meta .project-people {
      font-size: 1rem;
      color: #234375;
      font-weight: 500;
      margin-bottom: 0.2rem;
    }
    .project-meta .project-people span {
      display: block;
      margin-bottom: 0.3em;
    }
    .project-meta .project-timescale {
      font-size: 0.97rem;
      color: #3a4a6b;
      margin-bottom: 0.2rem;
    }
    .project-meta .project-outputs {
      font-size: 0.97rem;
      color: #234375;
      margin-top: 0.5rem;
    }
    .project-meta .project-outputs a {
      color: #234375;
      text-decoration: underline;
    }
    .project-meta .project-outputs a:hover {
      color: #1a5276;
    }
    h2 {
      color: #234375;
      font-size: 1.25rem;
      font-weight: 600;
      margin-top: 2.2rem;
      margin-bottom: 0.7rem;
      letter-spacing: 0.1px;
    }
    ul {
      padding-left: 1.3rem;
      margin-bottom: 1.2rem;
    }
    li {
      margin-bottom: 0.5rem;
    }
    .highlight-box {
      background: #f5f3ff;
      border-left: 4px solid #8b5cf6;
      padding: 1rem 1.2rem;
      border-radius: 0 8px 8px 0;
      margin: 1.5rem 0;
    }
    .highlight-box h4 {
      margin: 0 0 0.5rem 0;
      color: #6d28d9;
    }
    .contribution-list {
      display: flex;
      flex-direction: column;
      gap: 1rem;
      margin: 1.5rem 0;
    }
    .contribution-item {
      background: #fff;
      border-radius: 10px;
      padding: 1.2rem;
      box-shadow: 0 2px 6px rgba(35,67,117,0.07);
      border-left: 4px solid #8b5cf6;
    }
    .contribution-item h5 {
      margin: 0 0 0.4rem 0;
      color: #234375;
      font-size: 1rem;
    }
    .contribution-item p {
      margin: 0;
      font-size: 0.92rem;
      color: #3a4a6b;
    }
    .status-badge {
      display: inline-block;
      background: #fef3c7;
      color: #92400e;
      padding: 0.3rem 0.8rem;
      border-radius: 20px;
      font-size: 0.85rem;
      font-weight: 600;
      margin-bottom: 1rem;
    }
    .cosupervised-badge {
      display: inline-block;
      background: #e0e7ff;
      color: #3730a3;
      padding: 0.3rem 0.8rem;
      border-radius: 20px;
      font-size: 0.85rem;
      font-weight: 600;
      margin-left: 0.5rem;
    }
    @media (max-width: 900px) {
      main {
        flex-direction: column;
        gap: 1.5rem;
        padding: 1.2rem 0.7rem 1.2rem 0.7rem;
      }
      .project-meta {
        max-width: 100%;
        width: 100%;
        margin: 0;
      }
      .hero-section {
        min-height: 200px;
        border-radius: 16px;
      }
      .hero-content h1 {
        font-size: 1.5rem;
      }
    }
    .main-hero-wrapper {
      max-width: 1100px;
      margin: 0 auto;
      padding-left: 2rem;
      padding-right: 2rem;
    }
  </style>
</head>
<body>
  <div class="banner">
    <div class="banner-inner">
      <a href="index.html">
        <img src="./assets/images/Cardiff_University_(logo).svg.png" alt="Cardiff University Logo">
        <span>Alia I. Abdelmoty</span>
      </a>
      <nav>
        <a href="index.html#biography">Profile</a>
        <a href="about.html">About</a>
        <a href="index.html#research-areas">Research Areas</a>
        <a href="projects.html">Research Projects</a>
        <a href="publications.html">Publications</a>
        <a href="students.html">Students</a>
      </nav>
    </div>
  </div>
  <div class="main-hero-wrapper">
    <div class="hero-section">
      <div class="hero-content">
        <div class="hero-icon">‚öñÔ∏è</div>
        <h1>Gender-typed Preference Bias in Recommender Systems</h1>
        <div class="subtitle">Investigating How Demographic-Targeted Items Affect Recommendation Fairness</div>
      </div>
    </div>
  </div>
  <main>
    <section class="project-main">
      <span class="status-badge">üî¨ Ongoing Research</span>
      <span class="cosupervised-badge">Co-supervised</span>
      
      <p>
        This research investigates a novel and unexplored question in recommender systems: <strong>Does the presence of gender-typed preferences distort or suppress the representation of more neutral preferences within a recommender model?</strong>
      </p>
      <p>
        This is particularly relevant in multi-domain data where strongly gender-targeted items (e.g., cosmetics) exist alongside more general-audience items (e.g., science books). The research examines whether recommender systems inadvertently narrow exposure diversity by over-emphasising demographic signals.
      </p>

      <h2>Research Focus</h2>
      
      <div class="highlight-box">
        <h4>Core Research Question</h4>
        <p>When recommender models learn from data containing both gender-typed and gender-neutral items, do the gender-typed preferences act as proxies that bias recommendations away from neutral items?</p>
      </div>

      <h2>Research Approach</h2>
      <p>The research follows a systematic methodology:</p>
      <ul>
        <li><strong>Identify gender-typed preferences:</strong> Examine whether specific items or groups are statistically associated with particular genders</li>
        <li><strong>Detect proxy usage:</strong> Show that latent gender signals in data are used as proxies within recommendation models</li>
        <li><strong>Prove bias exists:</strong> Demonstrate that recommendations are biased towards gender-typed items</li>
        <li><strong>Analyse impact:</strong> Examine whether gender-neutral preferences are suppressed, narrowing exposure diversity</li>
        <li><strong>Counterfactual testing:</strong> Test whether recommendations for non-gender-typed items improve when trained in isolation</li>
      </ul>

      <h2>Key Contributions</h2>
      
      <div class="contribution-list">
        <div class="contribution-item">
          <h5>Impact Identification</h5>
          <p>Identifying how gender-typed preferences affect neutral item recommendations, revealing potential harm to recommendation diversity.</p>
        </div>
        <div class="contribution-item">
          <h5>Reproducible Framework</h5>
          <p>A reproducible framework for analysing demographic-typed preference biases that can be generalised to other demographics and datasets.</p>
        </div>
        <div class="contribution-item">
          <h5>Mitigation Strategies</h5>
          <p>Strategies for mitigating bias to promote more balanced exposure across user groups and content types.</p>
        </div>
      </div>

      <h2>Broader Implications</h2>
      <p>
        While this research focuses on gender as a demographic dimension, the framework and findings have broader implications:
      </p>
      <ul>
        <li><strong>Generalisability:</strong> The methodology can be applied to other demographic dimensions where item targeting occurs</li>
        <li><strong>Fairness in AI:</strong> Contributes to understanding how algorithmic systems can inadvertently reinforce demographic biases</li>
        <li><strong>Exposure Diversity:</strong> Addresses concerns about filter bubbles and narrowing of user exposure to diverse content</li>
        <li><strong>Responsible AI:</strong> Provides tools for auditing and improving fairness in recommendation systems</li>
      </ul>

      <h2>Context</h2>
      <p>
        This research sits at the intersection of recommender systems, fairness in machine learning, and computational social science. As recommender systems become increasingly influential in shaping user choices and experiences, understanding and mitigating their biases becomes critical for ensuring equitable outcomes.
      </p>
    </section>
    <aside class="project-meta">
      <h3>Tags</h3>
      <div class="project-tags">
        <span>Recommender Systems</span>
        <span>Algorithmic Bias</span>
        <span>Fairness in AI</span>
        <span>Gender Bias</span>
        <span>Machine Learning</span>
        <span>Exposure Diversity</span>
        <span>Responsible AI</span>
      </div>
      <h3>People</h3>
      <div class="project-people">
        <span>Sarah Parry</span>
        <span>Dr. Sylwia Polberg-Riener (Main Supervisor)</span>
        <span>Dr. Alia I. Abdelmoty (Co-supervisor)</span>
      </div>
      <h3>Time Scale</h3>
      <div class="project-timescale">
        PhD ongoing
      </div>
      <h3>Supervision</h3>
      <div class="project-outputs">
        <p style="margin: 0;">This is a co-supervised project with <a href="https://profiles.cardiff.ac.uk/staff/polbergs">Dr. Sylwia Polberg-Riener</a> as main supervisor.</p>
      </div>
      <h3>Related Area</h3>
      <div class="project-outputs">
        <a href="area4.html">Human-Centred AI & Social Computing</a>
      </div>
    </aside>
  </main>
</body>
</html>
